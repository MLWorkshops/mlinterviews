{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medium-cameroon",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial: An Introduction to Neural Networks\n",
    "\n",
    "In this tutorial you are going to learn the basics of neural networks. We will walk through each of the different parts that make up a neural network. In the end, we will put these parts together to create a model that can classify animals from a zoo dataset.\n",
    "\n",
    "The model will be developed from first principles using `Numpy`. This means we can see the inner workers of the neural network and how each part works together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "headed-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-crystal",
   "metadata": {},
   "source": [
    "## What is a neural network?\n",
    "So, what is a neural network. A neural network can be thought of as a more complicated linear equation.\n",
    "\n",
    "$y = m*x + b$\n",
    "\n",
    "Given some input (`x`), the model applies some weights (`m`) and biases (`b`) to predict an outcome, `y`.\n",
    "\n",
    "But, why is it called 'neural'? That seems to imply something related to the brain. For that, we need to introduce the perceptron.\n",
    "\n",
    "## What is a perceptron?\n",
    "The perceptron is the most basic unit of a neural network. It functions much like a neuron in our brain. Each neuron in our brain reserves signals from dendrites. Depending on the signals received, the neuron will fire or remain quite.\n",
    "\n",
    "The perceptron functions in much the same way. Each perceptron receives inputs from adjoining perceptrons. It will then combine these inputs and output either zero or a non-zero value. The functions that are used to make these decisions are called activation functions. Let's take a look at a couple of these activation functions.\n",
    "\n",
    "### Sigmoid Activation\n",
    "This activation function sets all inputs to values between 0 and 1. It does this using an exponential function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(Z):\n",
    "    activation = 1/(1 + np.exp(-1*Z))\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-assistant",
   "metadata": {},
   "source": [
    "### Relu Activation\n",
    "This activation function sets all negative values to 0 and otherwise returns the positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disciplinary-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(Z):\n",
    "    activation = np.maximum(0.0, Z)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-nightmare",
   "metadata": {},
   "source": [
    "### Softmax Function\n",
    "In our model, we are going to perform classification. Therefore, the neural network needs a way to predict a class as output, given some input features. This can be achieved by using a softmax function, which assigns a probability to each class. All probabibilities add up to one. The class with the highest probability is assigned the prediction for that class. The hidden layers allow the neural network to learn complex relationships between the input features to help it make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moved-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z))\n",
    "    activation = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-princeton",
   "metadata": {},
   "source": [
    "### Connecting Perceptrons\n",
    "Now that we have the 'neurons' (perceptrons) of the neural network, we need to create the network by connecting perceptrons together. Neurons are aligned in layers. The features are received as inputs to the initial layer. The final layer returns a prediction for the model. Inbetween are hidden layers. They are called hidden because we do not have access to information passed to these neurons. Let's define the architecture that we will use for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "packed-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 20\n",
    "NUM_CLASSES = 7\n",
    "LAYER_SIZES = [25, 25]\n",
    "\n",
    "LAYER_SIZES.insert(0, NUM_FEATURES)\n",
    "\n",
    "LAYER_SIZES.append(NUM_CLASSES)\n",
    "\n",
    "LAYER_ACTIVATIONS = ['relu', 'relu', 'softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afraid-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The layer sizes include: [20, 25, 25, 7].\n"
     ]
    }
   ],
   "source": [
    "print(f'The layer sizes include: {LAYER_SIZES}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-arena",
   "metadata": {},
   "source": [
    "Out dataset contains 20 features, so that is the input. The first and second layers contain 25 neurons. The final layer is the softmax layer, with seven outputs, one of each type of animal being predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-strip",
   "metadata": {},
   "source": [
    "### How are values passed between layers?\n",
    "\n",
    "Mathematically, this is done by using a weighted sum function. For each layer, the inputs to the perceptrons are multiplied by a weight. The weighted inputs are then added together. Finally, a bias term is added to the sum. This can be done exhaustively. But, a more elagant way is using linear algebra. Here is an example using numpy:\n",
    "\n",
    "`Z = np.dot(np.transpose(W), X) + b`\n",
    "\n",
    "`Z` is now a vector of size equal to the number of neurons in the layer. The vector `Z` now passes through an activation function before being passed to the next layer in the neural network.\n",
    "\n",
    "### Layer Initialization\n",
    "One of the most import steps in setting up a neural network is initiating the weights and biases. Basically, the neural network needs a starting point at which to begin it's learning process. The choice of initial values is very important. If all values are the same, then the outputs to each hidden layer will be the same. This will prevent each neuron in the hidden layer from learning anything useful. To prevent this problem, the weights and biases are initialized to small values. Let's initialize our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electoral-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network():\n",
    "    architecture = {}\n",
    "    for layer in range(1, len(LAYER_SIZES)):\n",
    "        architecture[f'layer_{layer}'] = {\n",
    "            'W': np.random.randn(LAYER_SIZES[layer],\n",
    "                                 LAYER_SIZES[layer-1]) * 0.1,\n",
    "            'b': np.random.randn(LAYER_SIZES[layer], 1) * 0.1,\n",
    "            'activation': LAYER_ACTIVATIONS[layer-1]\n",
    "        }\n",
    "    return architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crazy-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = initialize_network()\n",
    "# pprint.pprint(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-category",
   "metadata": {},
   "source": [
    "### Single Forward Pass\n",
    "Ok, now we have defined our neural network architecture and have initialized all weights and biases. We now need to define a function that will pass values from layer to layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_map = {\n",
    "    'sigmoid': sigmoid_activation,\n",
    "    'relu': relu_activation,\n",
    "    'softmax': softmax_activation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacterial-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_forward_pass(A_previous, W, b, activation):\n",
    "    try:\n",
    "        act_function = act_map[activation]\n",
    "    except KeyError:\n",
    "        print(f'The activation {activation} is not recognized.\\nIt must be one of the following: {list(act_map.keys())}')\n",
    "        return None\n",
    "    \n",
    "    Z = np.dot(W, A_previous) + b\n",
    "    A = act_function(Z)\n",
    "    \n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-rebound",
   "metadata": {},
   "source": [
    "This function using linear algebra to perform the weighted sum for each layer that was discussed above. It outputs the activated outputs `A` and the non-activated outputs `Z`.\n",
    "\n",
    "### Full Foward Pass\n",
    "In the next function I define, we loop through each layer in the network and perform a forward pass using `single_forward_pass()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naval-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_sigmoid(dA, Z):\n",
    "    sigmoid = sigmoid_activation(Z)\n",
    "    dZ = dA * sigmoid * (1.0 - sigmoid)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extraordinary-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_softmax(dA, Z):\n",
    "    softmax = softmax_activation(Z)\n",
    "    dZ = dA * softmax * (1.0 - softmax)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adapted-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_relu(dA, Z):\n",
    "    dZ = np.copy(dA)\n",
    "    dZ[Z <= 0.0] = 0.0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "material-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dZ_map = {\n",
    "    'sigmoid': dZ_sigmoid,\n",
    "    'relu': dZ_relu,\n",
    "    'softmax': dZ_softmax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vertical-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward_pass(X, network):\n",
    "    \n",
    "    cache = {}\n",
    "    A = np.transpose(X)\n",
    "    \n",
    "    for layer in range(1, len(network) + 1):\n",
    "        A_previous = A\n",
    "        A, Z = single_forward_pass(A_previous, \n",
    "                                   network[f'layer_{layer}']['W'], \n",
    "                                   network[f'layer_{layer}']['b'], \n",
    "                                   network[f'layer_{layer}']['activation'])\n",
    "        \n",
    "        cache[f'A_{layer-1}'] = A_previous\n",
    "        cache[f'Z_{layer}'] = Z\n",
    "        \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outside-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_cost(y_pred, y):\n",
    "    \n",
    "    cost = -1*np.mean(y * np.log(np.transpose(y_pred)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "traditional-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_backward_pass(dA, W, b, Z, A_previous, activation):\n",
    "    \n",
    "    try:\n",
    "        backprop_activation = dZ_map[activation]\n",
    "    except KeyError:\n",
    "        print(f'The backprop activation {activation} is not recognized.\\nIt must be one of the following: {list(dZ_map.keys())}')\n",
    "        return None\n",
    "    \n",
    "    m = A_previous.shape[1]\n",
    "    \n",
    "    dZ = backprop_activation(dA, Z)\n",
    "    \n",
    "    dW = np.dot(dZ, np.transpose(A_previous)) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_previous = np.dot(np.transpose(dW), dZ)\n",
    "    \n",
    "    return dA_previous, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "labeled-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_pass(y_pred, y, cache, network):\n",
    "    \n",
    "    stored_grads = {}\n",
    "    m = y.shape[1]\n",
    "    \n",
    "    dA_previous = y_pred - np.transpose(y)\n",
    "    \n",
    "    for layer in reversed(range(1, len(network) + 1)):\n",
    "        activation = network[f'layer_{layer}']['activation']\n",
    "        layer_previous = layer - 1\n",
    "        \n",
    "        dA = dA_previous\n",
    "        \n",
    "        A_previous = cache[f'A_{layer_previous}']\n",
    "        Z = cache[f'Z_{layer}']\n",
    "        W = network[f'layer_{layer}']['W']\n",
    "        b = network[f'layer_{layer}']['b']\n",
    "        \n",
    "        dA_previous, dW, db = single_backward_pass(dA, W, b, Z, A_previous, activation)\n",
    "        stored_grads[f'dW_{layer}'] = dW\n",
    "        stored_grads[f'db_{layer}'] = db\n",
    "        \n",
    "    return stored_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "removable-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_network(network, stored_grads, learning_rate):\n",
    "    for layer in range(1, len(network) + 1):\n",
    "        network[f'layer_{layer}']['W'] = network[f'layer_{layer}']['W'] - learning_rate * stored_grads[f'dW_{layer}']\n",
    "        network[f'layer_{layer}']['b'] = network[f'layer_{layer}']['b'] - learning_rate * stored_grads[f'db_{layer}']\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "medical-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_label_predictions(y_pred):\n",
    "    y_pred_transpose = np.transpose(y_pred)\n",
    "    y_pred_flat = np.argmax(y_pred_transpose, 1)\n",
    "    return y_pred_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "killing-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y):\n",
    "    y_pred_transpose = np.transpose(y_pred)\n",
    "    y_pred_flat = np.argmax(y_pred_transpose, 1)\n",
    "    y_flat = np.argmax(y, 1)\n",
    "    accuracy = np.mean(y_pred_flat == y_flat)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "guided-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X, y, network):\n",
    "    \n",
    "    stored_cost = []\n",
    "    \n",
    "    for epoch in range(HYPER_PARAMS['epochs']):\n",
    "        y_pred, cache = full_forward_pass(X, network)\n",
    "        cost = compute_cross_entropy_cost(y_pred, y)\n",
    "        if epoch == 0:\n",
    "            print(f' * The initial cost is {cost:0.3f}.')\n",
    "        stored_cost.append(cost)\n",
    "        stored_grads = full_backward_pass(y_pred, y, cache, network)\n",
    "        network = update_network(network, stored_grads, HYPER_PARAMS['learning_rate'])\n",
    "    final_accuracy = compute_accuracy(y_pred, y)\n",
    "    print(f' * Final cost: {cost:0.3f}.')\n",
    "    print(f' * Final accuracy: {final_accuracy:0.3%}')\n",
    "    return network, stored_cost, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-panama",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "completed-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_values = []\n",
    "with open('./data/zoo.dat', 'r') as zoo_file:\n",
    "    for line in zoo_file:\n",
    "        if '@attribute' in line:\n",
    "            header_values.append(line.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "powerful-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/zoo.dat', skiprows=21, header=None, names=header_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tough-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hair</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feathers</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eggs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.495325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.493522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airborne</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.427750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aquatic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.481335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predator</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toothed</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backbone</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breathes</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.407844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venomous</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fins</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.376013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2.841584</td>\n",
       "      <td>2.033385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.439397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domestic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.336552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catsize</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.498314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2.831683</td>\n",
       "      <td>2.102709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "Hair      101.0  0.425743  0.496921  0.0  0.0  0.0  1.0  1.0\n",
       "Feathers  101.0  0.198020  0.400495  0.0  0.0  0.0  0.0  1.0\n",
       "Eggs      101.0  0.584158  0.495325  0.0  0.0  1.0  1.0  1.0\n",
       "Milk      101.0  0.405941  0.493522  0.0  0.0  0.0  1.0  1.0\n",
       "Airborne  101.0  0.237624  0.427750  0.0  0.0  0.0  0.0  1.0\n",
       "Aquatic   101.0  0.356436  0.481335  0.0  0.0  0.0  1.0  1.0\n",
       "Predator  101.0  0.554455  0.499505  0.0  0.0  1.0  1.0  1.0\n",
       "Toothed   101.0  0.603960  0.491512  0.0  0.0  1.0  1.0  1.0\n",
       "Backbone  101.0  0.821782  0.384605  0.0  1.0  1.0  1.0  1.0\n",
       "Breathes  101.0  0.792079  0.407844  0.0  1.0  1.0  1.0  1.0\n",
       "Venomous  101.0  0.079208  0.271410  0.0  0.0  0.0  0.0  1.0\n",
       "Fins      101.0  0.168317  0.376013  0.0  0.0  0.0  0.0  1.0\n",
       "Legs      101.0  2.841584  2.033385  0.0  2.0  4.0  4.0  8.0\n",
       "Tail      101.0  0.742574  0.439397  0.0  0.0  1.0  1.0  1.0\n",
       "Domestic  101.0  0.128713  0.336552  0.0  0.0  0.0  0.0  1.0\n",
       "Catsize   101.0  0.435644  0.498314  0.0  0.0  0.0  1.0  1.0\n",
       "Type      101.0  2.831683  2.102709  1.0  1.0  2.0  4.0  7.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-scott",
   "metadata": {},
   "source": [
    "### Separate Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "curious-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(columns='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acting-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-climate",
   "metadata": {},
   "source": [
    "### One-hot Encode Features\n",
    "All features except 'Legs' include 1-0 values. Since 'Legs' is a categorical variable, it needs to be one-hot encoded. We can do this using Pandas `get_dummies()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "incorporate-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_one_hot = pd.get_dummies(df_X, columns=['Legs'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "peripheral-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hair</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feathers</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eggs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.495325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.493522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airborne</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.427750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aquatic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.481335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predator</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toothed</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backbone</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breathes</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.407844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venomous</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fins</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.376013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.439397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domestic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.336552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catsize</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.498314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_2</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.444772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_5</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.099504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_6</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_8</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.140014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "Hair      101.0  0.425743  0.496921  0.0  0.0  0.0  1.0  1.0\n",
       "Feathers  101.0  0.198020  0.400495  0.0  0.0  0.0  0.0  1.0\n",
       "Eggs      101.0  0.584158  0.495325  0.0  0.0  1.0  1.0  1.0\n",
       "Milk      101.0  0.405941  0.493522  0.0  0.0  0.0  1.0  1.0\n",
       "Airborne  101.0  0.237624  0.427750  0.0  0.0  0.0  0.0  1.0\n",
       "Aquatic   101.0  0.356436  0.481335  0.0  0.0  0.0  1.0  1.0\n",
       "Predator  101.0  0.554455  0.499505  0.0  0.0  1.0  1.0  1.0\n",
       "Toothed   101.0  0.603960  0.491512  0.0  0.0  1.0  1.0  1.0\n",
       "Backbone  101.0  0.821782  0.384605  0.0  1.0  1.0  1.0  1.0\n",
       "Breathes  101.0  0.792079  0.407844  0.0  1.0  1.0  1.0  1.0\n",
       "Venomous  101.0  0.079208  0.271410  0.0  0.0  0.0  0.0  1.0\n",
       "Fins      101.0  0.168317  0.376013  0.0  0.0  0.0  0.0  1.0\n",
       "Tail      101.0  0.742574  0.439397  0.0  0.0  1.0  1.0  1.0\n",
       "Domestic  101.0  0.128713  0.336552  0.0  0.0  0.0  0.0  1.0\n",
       "Catsize   101.0  0.435644  0.498314  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_2    101.0  0.267327  0.444772  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_4    101.0  0.376238  0.486857  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_5    101.0  0.009901  0.099504  0.0  0.0  0.0  0.0  1.0\n",
       "Legs_6    101.0  0.099010  0.300165  0.0  0.0  0.0  0.0  1.0\n",
       "Legs_8    101.0  0.019802  0.140014  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_one_hot.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "environmental-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X_one_hot.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-stupid",
   "metadata": {},
   "source": [
    "### One-hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sapphire-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 unique classes for the labels, which are [1 4 7 2 6 3 5].\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(pd.unique(df_y))\n",
    "print(f'There are {NUM_CLASSES} unique classes for the labels, which are {pd.unique(df_y)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "technological-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(x):\n",
    "    encoded = np.zeros(NUM_CLASSES)\n",
    "    encoded[x-1] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "engaged-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_one_hot = df_y.apply(lambda x: encode_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "committed-possible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "1    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "2    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "Name: Type, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "editorial-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_y_one_hot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "according-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-adventure",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "recent-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS = {\n",
    "    'epochs': 10000,\n",
    "    'learning_rate': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "secondary-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * The initial cost is 0.454.\n",
      " * Final cost: 0.219.\n",
      " * Final accuracy: 44.554%\n"
     ]
    }
   ],
   "source": [
    "network, stored_cost, y_pred = train_nn(X, y, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "distinct-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_counts(y):\n",
    "    y_label_summary = pd.Series(y).value_counts(normalize=True).reset_index().sort_values(by='index')\n",
    "    y_label_summary.columns = ['Label', 'Fraction']\n",
    "    return y_label_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "attached-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_counts = compute_label_counts(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "stainless-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.405941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.198020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.049505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.128713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.099010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Fraction\n",
       "0      1  0.405941\n",
       "1      2  0.198020\n",
       "5      3  0.049505\n",
       "2      4  0.128713\n",
       "6      5  0.039604\n",
       "4      6  0.079208\n",
       "3      7  0.099010"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stable-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flat = flatten_label_predictions(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "induced-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_counts = compute_label_counts(y_pred_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "comprehensive-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.950495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Fraction\n",
       "0      0  0.950495\n",
       "1      2  0.029703\n",
       "2      4  0.009901\n",
       "3      6  0.009901"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-controversy",
   "metadata": {},
   "source": [
    "### Resources\n",
    "This notebook has been inspired by the Towards Data Science post [Let’s code a Neural Network in plain NumPy](https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795).\n",
    "\n",
    "Additional resources include:\n",
    "\n",
    "* [A Gentle Introduction to Cross-Entropy for Machine Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/).\n",
    "* [Creating a Neural Network from Scratch in Python: Multi-class Classification](https://stackabuse.com/creating-a-neural-network-from-scratch-in-python-multi-class-classification/).\n",
    "* [The Softmax Function Derivative (Part 1)](https://aimatters.wordpress.com/2019/06/17/the-softmax-function-derivative/).\n",
    "* [Understanding and implementing Neural Network with SoftMax in Python from scratch](http://www.adeveloperdiary.com/data-science/deep-learning/neural-network-with-softmax-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-witness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
