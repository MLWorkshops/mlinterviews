{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ethical-philippines",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 20\n",
    "NUM_CLASSES = 7\n",
    "LAYER_SIZES = [25, 25]\n",
    "\n",
    "LAYER_SIZES.insert(0, NUM_FEATURES)\n",
    "\n",
    "LAYER_SIZES.append(NUM_CLASSES)\n",
    "\n",
    "LAYER_ACTIVATIONS = ['relu', 'relu', 'softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The layer sizes include: [20, 25, 25, 7].\n"
     ]
    }
   ],
   "source": [
    "print(f'The layer sizes include: {LAYER_SIZES}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arranged-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network():\n",
    "    architecture = {}\n",
    "    for layer in range(1, len(LAYER_SIZES)):\n",
    "        architecture[f'layer_{layer}'] = {\n",
    "            'W': np.random.randn(LAYER_SIZES[layer],\n",
    "                                 LAYER_SIZES[layer-1]) * 0.1,\n",
    "            'b': np.random.randn(LAYER_SIZES[layer], 1) * 0.1,\n",
    "            'activation': LAYER_ACTIVATIONS[layer-1]\n",
    "        }\n",
    "    return architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "senior-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = initialize_network()\n",
    "# pprint.pprint(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capable-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(Z):\n",
    "    activation = 1/(1 + np.exp(-1*Z))\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "particular-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _softmax_activation(Z):\n",
    "    activation = np.exp(Z) / np.sum(np.exp(Z))\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stable-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z))\n",
    "    activation = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separated-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(Z):\n",
    "    activation = np.maximum(0.0, Z)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adverse-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_sigmoid(dA, Z):\n",
    "    sigmoid = sigmoid_activation(Z)\n",
    "    dZ = dA * sigmoid * (1.0 - sigmoid)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "structured-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_softmax(dA, Z):\n",
    "    sigmoid = sigmoid_activation(Z)\n",
    "    dZ = dA * sigmoid * (1.0 - sigmoid)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "iraqi-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dZ_softmax(Z):\n",
    "    softmax = softmax_activation(Z)\n",
    "    softmax_matrix = np.tile(softmax)\n",
    "    dZ = np.diag(softmax) - (softmax_matrix*np.transpose(softmax_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advisory-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dZ_relu(dA, Z):\n",
    "    dZ = np.copy(dA)\n",
    "    dZ[Z <= 0.0] = 0.0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "available-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_map = {\n",
    "    'sigmoid': sigmoid_activation,\n",
    "    'relu': relu_activation,\n",
    "    'softmax': softmax_activation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conventional-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "dZ_map = {\n",
    "    'sigmoid': dZ_sigmoid,\n",
    "    'relu': dZ_relu,\n",
    "    'softmax': dZ_softmax\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "heard-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_forward_pass(A_previous, W, b, activation):\n",
    "    try:\n",
    "        act_function = act_map[activation]\n",
    "    except KeyError:\n",
    "        print(f'The activation {activation} is not recognized.\\nIt must be one of the following: {list(act_map.keys())}')\n",
    "        return None\n",
    "    \n",
    "    Z = np.dot(W, A_previous) + b\n",
    "    A = act_function(Z)\n",
    "    \n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comparative-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward_pass(X, network):\n",
    "    \n",
    "    cache = {}\n",
    "    A = np.transpose(X)\n",
    "    \n",
    "    for layer in range(1, len(network) + 1):\n",
    "        A_previous = A\n",
    "        A, Z = single_forward_pass(A_previous, \n",
    "                                   network[f'layer_{layer}']['W'], \n",
    "                                   network[f'layer_{layer}']['b'], \n",
    "                                   network[f'layer_{layer}']['activation'])\n",
    "        \n",
    "        cache[f'A_{layer-1}'] = A_previous\n",
    "        cache[f'Z_{layer}'] = Z\n",
    "        \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tough-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_cost(y_pred, y):\n",
    "    \n",
    "    # cost = np.sum(-1*(y * np.log(np.transpose(y_pred))))\n",
    "    cost = -1*np.mean(y * np.log(np.transpose(y_pred)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "considerable-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_backward_pass(dA, W, b, Z, A_previous, activation):\n",
    "    \n",
    "    try:\n",
    "        backprop_activation = dZ_map[activation]\n",
    "    except KeyError:\n",
    "        print(f'The backprop activation {activation} is not recognized.\\nIt must be one of the following: {list(dZ_map.keys())}')\n",
    "        return None\n",
    "    \n",
    "    m = A_previous.shape[1]\n",
    "    \n",
    "    dZ = backprop_activation(dA, Z)\n",
    "    \n",
    "    dW = np.dot(dZ, np.transpose(A_previous)) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_previous = np.dot(np.transpose(dW), dZ)\n",
    "    \n",
    "    return dA_previous, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "derived-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_pass(y_pred, y, cache, network):\n",
    "    \n",
    "    stored_grads = {}\n",
    "    m = y.shape[1]\n",
    "    \n",
    "    dA_previous = y_pred - np.transpose(y)\n",
    "    \n",
    "    for layer in reversed(range(1, len(network) + 1)):\n",
    "        activation = network[f'layer_{layer}']['activation']\n",
    "        layer_previous = layer - 1\n",
    "        \n",
    "        dA = dA_previous\n",
    "        \n",
    "        A_previous = cache[f'A_{layer_previous}']\n",
    "        Z = cache[f'Z_{layer}']\n",
    "        W = network[f'layer_{layer}']['W']\n",
    "        b = network[f'layer_{layer}']['b']\n",
    "        \n",
    "        dA_previous, dW, db = single_backward_pass(dA, W, b, Z, A_previous, activation)\n",
    "        stored_grads[f'dW_{layer}'] = dW\n",
    "        stored_grads[f'db_{layer}'] = db\n",
    "        \n",
    "    return stored_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stunning-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_network(network, stored_grads, learning_rate):\n",
    "    for layer in range(1, len(network) + 1):\n",
    "        network[f'layer_{layer}']['W'] = network[f'layer_{layer}']['W'] - learning_rate * stored_grads[f'dW_{layer}']\n",
    "        network[f'layer_{layer}']['b'] = network[f'layer_{layer}']['b'] - learning_rate * stored_grads[f'db_{layer}']\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "august-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS = {\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "serious-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y):\n",
    "    y_pred_transpose = np.transpose(y_pred)\n",
    "    print(f'y_pred_transpose.shape: {y_pred_transpose.shape}')\n",
    "    print(f'y.shape: {y.shape}')\n",
    "    y_pred_flat = np.argmax(y_pred_transpose, 1)\n",
    "    print(f'np.max(y_pred_flat): {np.max(y_pred_flat)}')\n",
    "    y_flat = np.argmax(y, 1)\n",
    "    print(list(zip(y_pred_flat, y_flat)))\n",
    "    print(f'np.unique(y_pred_flat): {np.unique(y_pred_flat, return_counts=True)}')\n",
    "    print(f'np.unique(y_flat): {np.unique(y_flat, return_counts=True)}')\n",
    "    accuracy = np.mean(y_pred_flat == y_flat) / 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "continued-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X, y, network):\n",
    "    \n",
    "    stored_cost = []\n",
    "    \n",
    "    for epoch in range(HYPER_PARAMS['epochs']):\n",
    "        y_pred, cache = full_forward_pass(X, network)\n",
    "        cost = compute_cross_entropy_cost(y_pred, y)\n",
    "        # print(f' * The cost at epoch {epoch} is {cost:0.3f}.')\n",
    "        stored_cost.append(cost)\n",
    "        stored_grads = full_backward_pass(y_pred, y, cache, network)\n",
    "        network = update_network(network, stored_grads, HYPER_PARAMS['learning_rate'])\n",
    "    final_accuracy = compute_accuracy(y_pred, y)\n",
    "    print(f' * Final accuracy: {final_accuracy}')\n",
    "    return network, stored_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-windsor",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "**Plan:**\n",
    "1. Load data set.\n",
    "2. Split into labels and features.\n",
    "3. One-hot encode features.\n",
    "4. One-hot encode labels.\n",
    "5. Run through model.\n",
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expanded-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_values = []\n",
    "with open('./data/zoo.dat', 'r') as zoo_file:\n",
    "    for line in zoo_file:\n",
    "        if '@attribute' in line:\n",
    "            header_values.append(line.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "listed-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/zoo.dat', skiprows=21, header=None, names=header_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acting-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hair</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feathers</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eggs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.495325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.493522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airborne</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.427750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aquatic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.481335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predator</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toothed</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backbone</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breathes</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.407844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venomous</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fins</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.376013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2.841584</td>\n",
       "      <td>2.033385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.439397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domestic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.336552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catsize</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.498314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>101.0</td>\n",
       "      <td>2.831683</td>\n",
       "      <td>2.102709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "Hair      101.0  0.425743  0.496921  0.0  0.0  0.0  1.0  1.0\n",
       "Feathers  101.0  0.198020  0.400495  0.0  0.0  0.0  0.0  1.0\n",
       "Eggs      101.0  0.584158  0.495325  0.0  0.0  1.0  1.0  1.0\n",
       "Milk      101.0  0.405941  0.493522  0.0  0.0  0.0  1.0  1.0\n",
       "Airborne  101.0  0.237624  0.427750  0.0  0.0  0.0  0.0  1.0\n",
       "Aquatic   101.0  0.356436  0.481335  0.0  0.0  0.0  1.0  1.0\n",
       "Predator  101.0  0.554455  0.499505  0.0  0.0  1.0  1.0  1.0\n",
       "Toothed   101.0  0.603960  0.491512  0.0  0.0  1.0  1.0  1.0\n",
       "Backbone  101.0  0.821782  0.384605  0.0  1.0  1.0  1.0  1.0\n",
       "Breathes  101.0  0.792079  0.407844  0.0  1.0  1.0  1.0  1.0\n",
       "Venomous  101.0  0.079208  0.271410  0.0  0.0  0.0  0.0  1.0\n",
       "Fins      101.0  0.168317  0.376013  0.0  0.0  0.0  0.0  1.0\n",
       "Legs      101.0  2.841584  2.033385  0.0  2.0  4.0  4.0  8.0\n",
       "Tail      101.0  0.742574  0.439397  0.0  0.0  1.0  1.0  1.0\n",
       "Domestic  101.0  0.128713  0.336552  0.0  0.0  0.0  0.0  1.0\n",
       "Catsize   101.0  0.435644  0.498314  0.0  0.0  0.0  1.0  1.0\n",
       "Type      101.0  2.831683  2.102709  1.0  1.0  2.0  4.0  7.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-detector",
   "metadata": {},
   "source": [
    "### Separate Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "demonstrated-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(columns='Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sized-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-plane",
   "metadata": {},
   "source": [
    "### One-hot Encode Features\n",
    "All features except 'Legs' include 1-0 values. Since 'Legs' is a categorical variable, it needs to be one-hot encoded. We can do this using Pandas `get_dummies()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "novel-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_one_hot = pd.get_dummies(df_X, columns=['Legs'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "described-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hair</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.496921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feathers</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.400495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eggs</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.495325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milk</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.493522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airborne</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.427750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aquatic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.481335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predator</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toothed</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backbone</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.384605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breathes</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.407844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venomous</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.271410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fins</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.376013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.439397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domestic</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.336552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catsize</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.435644</td>\n",
       "      <td>0.498314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_2</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.267327</td>\n",
       "      <td>0.444772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_4</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_5</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.099504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_6</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.300165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legs_8</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.140014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std  min  25%  50%  75%  max\n",
       "Hair      101.0  0.425743  0.496921  0.0  0.0  0.0  1.0  1.0\n",
       "Feathers  101.0  0.198020  0.400495  0.0  0.0  0.0  0.0  1.0\n",
       "Eggs      101.0  0.584158  0.495325  0.0  0.0  1.0  1.0  1.0\n",
       "Milk      101.0  0.405941  0.493522  0.0  0.0  0.0  1.0  1.0\n",
       "Airborne  101.0  0.237624  0.427750  0.0  0.0  0.0  0.0  1.0\n",
       "Aquatic   101.0  0.356436  0.481335  0.0  0.0  0.0  1.0  1.0\n",
       "Predator  101.0  0.554455  0.499505  0.0  0.0  1.0  1.0  1.0\n",
       "Toothed   101.0  0.603960  0.491512  0.0  0.0  1.0  1.0  1.0\n",
       "Backbone  101.0  0.821782  0.384605  0.0  1.0  1.0  1.0  1.0\n",
       "Breathes  101.0  0.792079  0.407844  0.0  1.0  1.0  1.0  1.0\n",
       "Venomous  101.0  0.079208  0.271410  0.0  0.0  0.0  0.0  1.0\n",
       "Fins      101.0  0.168317  0.376013  0.0  0.0  0.0  0.0  1.0\n",
       "Tail      101.0  0.742574  0.439397  0.0  0.0  1.0  1.0  1.0\n",
       "Domestic  101.0  0.128713  0.336552  0.0  0.0  0.0  0.0  1.0\n",
       "Catsize   101.0  0.435644  0.498314  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_2    101.0  0.267327  0.444772  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_4    101.0  0.376238  0.486857  0.0  0.0  0.0  1.0  1.0\n",
       "Legs_5    101.0  0.009901  0.099504  0.0  0.0  0.0  0.0  1.0\n",
       "Legs_6    101.0  0.099010  0.300165  0.0  0.0  0.0  0.0  1.0\n",
       "Legs_8    101.0  0.019802  0.140014  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_one_hot.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sought-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X_one_hot.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-advice",
   "metadata": {},
   "source": [
    "### One-hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "regulation-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 unique classes for the labels, which are [1 4 7 2 6 3 5].\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(pd.unique(df_y))\n",
    "print(f'There are {NUM_CLASSES} unique classes for the labels, which are {pd.unique(df_y)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attractive-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(x):\n",
    "    encoded = np.zeros(NUM_CLASSES)\n",
    "    encoded[x-1] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "freelance-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_one_hot = df_y.apply(lambda x: encode_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "textile-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "1    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "2    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "3    [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "4    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
       "Name: Type, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "grave-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_y_one_hot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "effective-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "infinite-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "injured-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS = {\n",
    "    'epochs': 1000,\n",
    "    'learning_rate': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "appreciated-vancouver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cultural-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 7)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adaptive-activity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "moving-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_transpose.shape: (101, 7)\n",
      "y.shape: (101, 7)\n",
      "np.max(y_pred_flat): 3\n",
      "[(0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 3), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 5), (3, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 3), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 5), (0, 3), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 5), (0, 5), (0, 0), (0, 2), (0, 2), (0, 2), (0, 4), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 5), (0, 5), (0, 2), (0, 4), (0, 0), (0, 0), (0, 0), (0, 0), (0, 3), (0, 6), (0, 1), (0, 1), (0, 5), (0, 5), (0, 4), (0, 4)]\n",
      "np.unique(y_pred_flat): (array([0, 3]), array([100,   1]))\n",
      "np.unique(y_flat): (array([0, 1, 2, 3, 4, 5, 6]), array([41, 20,  5, 13,  4,  8, 10]))\n",
      " * Final accuracy: 0.0040594059405940595\n"
     ]
    }
   ],
   "source": [
    "network, stored_cost = train_nn(X, y, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "likely-suffering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "exclusive-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "regular-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index      Type\n",
      "0      1  0.405941\n",
      "1      2  0.198020\n",
      "5      3  0.049505\n",
      "2      4  0.128713\n",
      "6      5  0.039604\n",
      "4      6  0.079208\n",
      "3      7  0.099010\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(df_y).value_counts(normalize=True).reset_index().sort_values(by='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-joining",
   "metadata": {},
   "source": [
    "### Resources\n",
    "This notebook has been inspired by the Towards Data Science post [Letâ€™s code a Neural Network in plain NumPy](https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795).\n",
    "\n",
    "Additional resources include:\n",
    "\n",
    "* [A Gentle Introduction to Cross-Entropy for Machine Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/).\n",
    "* [Creating a Neural Network from Scratch in Python: Multi-class Classification](https://stackabuse.com/creating-a-neural-network-from-scratch-in-python-multi-class-classification/).\n",
    "* [The Softmax Function Derivative (Part 1)](https://aimatters.wordpress.com/2019/06/17/the-softmax-function-derivative/).\n",
    "* [Understanding and implementing Neural Network with SoftMax in Python from scratch](http://www.adeveloperdiary.com/data-science/deep-learning/neural-network-with-softmax-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-cinema",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
